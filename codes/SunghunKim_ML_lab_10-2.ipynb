{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML lab10: Dropout, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout으로 과적합을 예방, Adam으로 다른 GradientDescent외의 Optimizer사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-84693db31563>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-84693db31563>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-1-84693db31563>:60: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 0.469264611\n",
      "Epoch: 0002 cost = 0.169099641\n",
      "Epoch: 0003 cost = 0.130174666\n",
      "Epoch: 0004 cost = 0.107074519\n",
      "Epoch: 0005 cost = 0.089947981\n",
      "Epoch: 0006 cost = 0.082481811\n",
      "Epoch: 0007 cost = 0.078104355\n",
      "Epoch: 0008 cost = 0.066031707\n",
      "Epoch: 0009 cost = 0.064497212\n",
      "Epoch: 0010 cost = 0.061351487\n",
      "Epoch: 0011 cost = 0.056787355\n",
      "Epoch: 0012 cost = 0.053549177\n",
      "Epoch: 0013 cost = 0.049904058\n",
      "Epoch: 0014 cost = 0.048674812\n",
      "Epoch: 0015 cost = 0.046641941\n",
      "Learning Finished!\n",
      "Accuracy: 0.9829\n",
      "Label:  [9]\n",
      "Prediction:  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lab 10 MNIST and Dropout\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch normalization 연습해볼것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
