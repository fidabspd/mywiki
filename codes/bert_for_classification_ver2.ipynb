{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efa71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225e7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import transformers\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a28b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "\n",
    "train_origin = pd.read_csv(data_path+'train_data.csv')\n",
    "test_origin = pd.read_csv(data_path+'test_data.csv')\n",
    "topic_dict_origin = pd.read_csv(data_path+'topic_dict.csv')\n",
    "sample_submission_origin = pd.read_csv(data_path+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af7c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_origin.copy()\n",
    "test = test_origin.copy()\n",
    "topic_dict = topic_dict_origin.copy()\n",
    "sample_submission = sample_submission_origin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4360e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(\n",
    "    'kykim/bert-kor-base',\n",
    "    cache_dir = '../tokenizer/kykim/bert-kor-base',\n",
    "    do_lower_case = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d990158",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {}\n",
    "data_config['max_length'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df6de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    text = re.sub('[^a-z가-힣]', ' ', text.lower())\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e352a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['title'].apply(cleaning_text)\n",
    "X_train = X_train.values.tolist()\n",
    "\n",
    "X_train_encoded = tokenizer(\n",
    "    X_train,\n",
    "    padding = 'max_length',\n",
    "    truncation = True,\n",
    "    max_length = data_config['max_length'],\n",
    "    return_tensors = 'tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8825312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['topic_idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6dffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = transformers.TFBertForSequenceClassification.from_pretrained(\n",
    "    'kykim/bert-kor-base', \n",
    "    cache_dir = '../model/kykim/bert-kor-base/cache/',\n",
    "    output_hidden_states=False,\n",
    "    output_attentions=False,\n",
    "    use_cache = False,\n",
    "    num_labels = 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e08f370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(learning_rate=3e-5, print_summary=False):\n",
    "\n",
    "    input_ids = Input(batch_shape=(None, data_config['max_length']), dtype=tf.int32, name='input_ids')\n",
    "    input_masks = Input(batch_shape=(None, data_config['max_length']), dtype=tf.int32, name='attention_masks')\n",
    "    bert_outputs = bert_model([input_ids, input_masks])['logits']\n",
    "    dropout_0 = Dropout(0.2, name='dropout_0')(bert_outputs)\n",
    "#     dense_0 = Dense(512, activation='relu', name='dense_0')(dropout_0)\n",
    "#     dropout_1 = Dropout(0.1, name='dropout_1')(dense_0)\n",
    "#     dense_1 = Dense(256, activation='relu', name='dense_1')(dropout_1)\n",
    "#     dropout_2 = Dropout(0.1, name='dropout_2')(dense_1)\n",
    "#     dense_2 = Dense(128, activation='relu', name='dense_2')(dropout_2)\n",
    "#     dropout_3 = Dropout(0.1, name='dropout_3')(dense_2)\n",
    "#     dense_3 = Dense(32, activation='relu', name='dense_3')(dropout_3)\n",
    "#     dropout_4 = Dropout(0.1, name='dropout_4')(dense_3)\n",
    "#     outputs = Dense(7, activation='softmax', name='outputs')(dropout_4)\n",
    "    bn_0 = BatchNormalization()(dropout_0)\n",
    "    outputs = Dense(7, activation='softmax', name='outputs')(bn_0)\n",
    "\n",
    "    model = Model(\n",
    "        inputs = [input_ids, input_masks],\n",
    "        outputs = outputs,\n",
    "        name = 'Bert_Classification'\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        optimizer = optimizer, \n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "\n",
    "    if print_summary:\n",
    "        model.summary(line_length=150)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee92c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f782ab3aba8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f78289e8110> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f782ab3aba8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f78289e8110> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Model: \"Bert_Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_for_sequence_classifica TFSequenceClassifier 118302727   input_ids[0][0]                  \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_0 (Dropout)             (None, 7)            0           tf_bert_for_sequence_classificati\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7)            28          dropout_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 7)            56          batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 118,302,811\n",
      "Trainable params: 70\n",
      "Non-trainable params: 118,302,741\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = set_model(learning_rate=9e-5)\n",
    "model.layers[2].trainable = False\n",
    "for i in range(len(model.layers[2].weights)):\n",
    "    model.layers[2].weights[i]._trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01be603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/pooler/dense/bias:0', 'tf_bert_for_sequence_classification/classifier/kernel:0', 'tf_bert_for_sequence_classification/classifier/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/pooler/dense/bias:0', 'tf_bert_for_sequence_classification/classifier/kernel:0', 'tf_bert_for_sequence_classification/classifier/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 8s 139ms/step - loss: 2.4432 - accuracy: 0.1368\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = [X_train_encoded['input_ids'][:5000], X_train_encoded['attention_mask'][:5000]], \n",
    "    y = y_train[:5000],\n",
    "    epochs = 1,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea7c744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bert_Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_for_sequence_classifica TFSequenceClassifier 118302727   input_ids[0][0]                  \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_0 (Dropout)             (None, 7)            0           tf_bert_for_sequence_classificati\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7)            28          dropout_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 7)            56          batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 118,302,811\n",
      "Trainable params: 118,302,797\n",
      "Non-trainable params: 14\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[2].trainable = True\n",
    "\n",
    "for i in range(len(model.layers[2].weights))[-36:]:\n",
    "    model.layers[2].weights[i]._trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=3e-5)\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = optimizer, \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bebb4950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - ETA: 0s - loss: 1.2335 - accuracy: 0.5961WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "286/286 [==============================] - 68s 225ms/step - loss: 1.2335 - accuracy: 0.5961 - val_loss: 0.7194 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80692, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 2/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.8555 - accuracy: 0.7810 - val_loss: 0.6934 - val_accuracy: 0.8233\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.80692 to 0.82335, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 3/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.8035 - accuracy: 0.8006 - val_loss: 0.6608 - val_accuracy: 0.8348\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.82335 to 0.83485, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 4/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.7725 - accuracy: 0.8121 - val_loss: 0.6771 - val_accuracy: 0.8313\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.83485\n",
      "Epoch 5/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.7517 - accuracy: 0.8198 - val_loss: 0.6583 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.83485\n",
      "Epoch 6/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.7341 - accuracy: 0.8257 - val_loss: 0.6366 - val_accuracy: 0.8412\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.83485 to 0.84120, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 7/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.7210 - accuracy: 0.8273 - val_loss: 0.6299 - val_accuracy: 0.8421\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.84120 to 0.84208, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 8/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.7064 - accuracy: 0.8331 - val_loss: 0.6357 - val_accuracy: 0.8433\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.84208 to 0.84328, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 9/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6987 - accuracy: 0.8349 - val_loss: 0.6177 - val_accuracy: 0.8443\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.84328 to 0.84427, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 10/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.6862 - accuracy: 0.8407 - val_loss: 0.6191 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.84427 to 0.84569, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 11/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6749 - accuracy: 0.8428 - val_loss: 0.6049 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.84569 to 0.84788, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 12/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6701 - accuracy: 0.8430 - val_loss: 0.6145 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84788\n",
      "Epoch 13/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.6623 - accuracy: 0.8451 - val_loss: 0.6031 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84788\n",
      "Epoch 14/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.6553 - accuracy: 0.8491 - val_loss: 0.5997 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84788\n",
      "Epoch 15/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.6480 - accuracy: 0.8506 - val_loss: 0.6053 - val_accuracy: 0.8442\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84788\n",
      "Epoch 16/30\n",
      "286/286 [==============================] - 61s 214ms/step - loss: 0.6464 - accuracy: 0.8512 - val_loss: 0.5912 - val_accuracy: 0.8492\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84788 to 0.84920, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 17/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6387 - accuracy: 0.8521 - val_loss: 0.5952 - val_accuracy: 0.8496\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84920 to 0.84963, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 18/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6354 - accuracy: 0.8555 - val_loss: 0.5952 - val_accuracy: 0.8465\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84963\n",
      "Epoch 19/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6312 - accuracy: 0.8570 - val_loss: 0.5870 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84963 to 0.84974, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 20/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6287 - accuracy: 0.8579 - val_loss: 0.5885 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84974\n",
      "Epoch 21/30\n",
      "286/286 [==============================] - 61s 214ms/step - loss: 0.6254 - accuracy: 0.8582 - val_loss: 0.5955 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84974\n",
      "Epoch 22/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6243 - accuracy: 0.8576 - val_loss: 0.5874 - val_accuracy: 0.8476\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84974\n",
      "Epoch 23/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6188 - accuracy: 0.8610 - val_loss: 0.5790 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.84974 to 0.85106, saving model to ../model/bert_kor_base_for_classification_fine_tuning_2.h5\n",
      "Epoch 24/30\n",
      "286/286 [==============================] - 62s 216ms/step - loss: 0.6195 - accuracy: 0.8589 - val_loss: 0.5809 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85106\n",
      "Epoch 25/30\n",
      "286/286 [==============================] - 62s 215ms/step - loss: 0.6153 - accuracy: 0.8623 - val_loss: 0.5840 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85106\n",
      "Epoch 26/30\n",
      "286/286 [==============================] - 61s 214ms/step - loss: 0.6136 - accuracy: 0.8603 - val_loss: 0.5750 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85106\n",
      "Epoch 27/30\n",
      "286/286 [==============================] - 61s 212ms/step - loss: 0.6119 - accuracy: 0.8611 - val_loss: 0.5830 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85106\n",
      "Epoch 28/30\n",
      "286/286 [==============================] - 61s 215ms/step - loss: 0.6117 - accuracy: 0.8616 - val_loss: 0.5799 - val_accuracy: 0.8489\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85106\n",
      "Epoch 29/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6087 - accuracy: 0.8636 - val_loss: 0.5850 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85106\n",
      "Epoch 30/30\n",
      "286/286 [==============================] - 61s 213ms/step - loss: 0.6049 - accuracy: 0.8639 - val_loss: 0.5822 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85106\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 5\n",
    ")\n",
    "model_check_point = ModelCheckpoint(\n",
    "    filepath = f'../model/bert_kor_base_for_classification_fine_tuning_{ver}.h5',\n",
    "    monitor = 'val_accuracy',\n",
    "    verbose = 1,\n",
    "    min_delta = 0.02,\n",
    "    mode = 'max',\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True\n",
    ")\n",
    "def scheduler(epoch, lr):\n",
    "    return lr * 0.9\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "history = model.fit(\n",
    "    x = [X_train_encoded['input_ids'], X_train_encoded['attention_mask']], \n",
    "    y = y_train,\n",
    "    epochs = 30,\n",
    "    batch_size = 128,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [early_stop, model_check_point, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abab8c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "best_model = set_model()\n",
    "best_model.load_weights(f'../model/bert_kor_base_for_classification_fine_tuning_{ver}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b66f1d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "train accuracy: 0.8989\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = best_model.predict([X_train_encoded['input_ids'], X_train_encoded['attention_mask']])\n",
    "y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(f'train accuracy: {accuracy_score(y_train, y_train_pred):.04f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2501c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test['title'].apply(cleaning_text)\n",
    "X_test = X_test.values.tolist()\n",
    "\n",
    "X_test_encoded = tokenizer(\n",
    "    X_test,\n",
    "    padding = 'max_length',\n",
    "    truncation = True,\n",
    "    max_length = data_config['max_length'],\n",
    "    return_tensors = 'tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b26f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict([X_test_encoded['input_ids'], X_test_encoded['attention_mask']])\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "sample_submission['topic_idx'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b4db88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission.to_csv(f'../submit/bert_kor_base_for_classification_{ver}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25013cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f'../submit/bert_kor_base_for_classification_{ver}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f36596f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31066193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification/bert/encoder/layer_._9/output/LayerNorm/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.8746WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "286/286 [==============================] - 66s 216ms/step - loss: 0.5750 - accuracy: 0.8746 - val_loss: 0.5732 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57321, saving model to ../model/bert_kor_base_for_classification_fine_tuning_3.h5\n",
      "Epoch 2/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5698 - accuracy: 0.8790 - val_loss: 0.5672 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57321 to 0.56716, saving model to ../model/bert_kor_base_for_classification_fine_tuning_3.h5\n",
      "Epoch 3/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5648 - accuracy: 0.8807 - val_loss: 0.5646 - val_accuracy: 0.8512\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56716 to 0.56461, saving model to ../model/bert_kor_base_for_classification_fine_tuning_3.h5\n",
      "Epoch 4/30\n",
      "286/286 [==============================] - 60s 212ms/step - loss: 0.5623 - accuracy: 0.8800 - val_loss: 0.5688 - val_accuracy: 0.8495\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.56461\n",
      "Epoch 5/30\n",
      "286/286 [==============================] - 60s 212ms/step - loss: 0.5606 - accuracy: 0.8832 - val_loss: 0.5712 - val_accuracy: 0.8476\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.56461\n",
      "Epoch 6/30\n",
      "286/286 [==============================] - 60s 210ms/step - loss: 0.5592 - accuracy: 0.8825 - val_loss: 0.5673 - val_accuracy: 0.8492\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.56461\n",
      "Epoch 7/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5613 - accuracy: 0.8817 - val_loss: 0.5672 - val_accuracy: 0.8488\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56461\n",
      "Epoch 8/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5611 - accuracy: 0.8820 - val_loss: 0.5683 - val_accuracy: 0.8485\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.56461\n",
      "Epoch 9/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5638 - accuracy: 0.8795 - val_loss: 0.5670 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56461\n",
      "Epoch 10/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5629 - accuracy: 0.8812 - val_loss: 0.5674 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56461\n",
      "Epoch 11/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5596 - accuracy: 0.8820 - val_loss: 0.5689 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.56461\n",
      "Epoch 12/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5653 - accuracy: 0.8770 - val_loss: 0.5669 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.56461\n",
      "Epoch 13/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5659 - accuracy: 0.8779 - val_loss: 0.5676 - val_accuracy: 0.8491\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.56461\n",
      "Epoch 14/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5659 - accuracy: 0.8796 - val_loss: 0.5675 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.56461\n",
      "Epoch 15/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5642 - accuracy: 0.8783 - val_loss: 0.5671 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.56461\n",
      "Epoch 16/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5685 - accuracy: 0.8767 - val_loss: 0.5655 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.56461\n",
      "Epoch 17/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5662 - accuracy: 0.8762 - val_loss: 0.5672 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.56461\n",
      "Epoch 18/30\n",
      "286/286 [==============================] - 60s 211ms/step - loss: 0.5678 - accuracy: 0.8769 - val_loss: 0.5686 - val_accuracy: 0.8481\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.56461\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 15\n",
    ")\n",
    "model_check_point = ModelCheckpoint(\n",
    "    filepath = f'../model/bert_kor_base_for_classification_fine_tuning_{ver}.h5',\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    min_delta = 0.02,\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=3e-5*0.1)\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = optimizer, \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch % 3 == 0:\n",
    "        return lr * 0.7\n",
    "    else:\n",
    "        return lr\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "history = model.fit(\n",
    "    x = [X_train_encoded['input_ids'], X_train_encoded['attention_mask']], \n",
    "    y = y_train,\n",
    "    epochs = 30,\n",
    "    batch_size = 128,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [early_stop, model_check_point, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ecb843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "best_model = set_model()\n",
    "best_model.load_weights(f'../model/bert_kor_base_for_classification_fine_tuning_{ver}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "428a0d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_model.predict([X_test_encoded['input_ids'], X_test_encoded['attention_mask']])\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "sample_submission['topic_idx'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf31e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(f'../submit/bert_kor_base_for_classification_{ver}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb2dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
